{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5f06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from random import sample\n",
    "import json\n",
    "import jsonlines as jl\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867adeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_DATA_TAGGED = r'./npf_dialogues_tagged.xlsx'\n",
    "NPF_DIALOGUE_JSON = r'./on-clean-texts/npf_dialogues.json'\n",
    "NPF_FAQ_JSON = r'./FAQ_NPF.json'\n",
    "QUESTION2FAQ = r'./question2id.json'\n",
    "ANSWER2FAQ = r'./answer2id.json'\n",
    "TRIPLET_DATA = r'./npf_dialogue_triplets.jsonl'\n",
    "\n",
    "ID = 'ID'\n",
    "DIALOGUE = 'Диалог'\n",
    "FAQ = 'FAQ'\n",
    "QUESTION = 'Вопрос'\n",
    "ANSWER = 'Ответ'\n",
    "\n",
    "OPERATOR = 'operator'\n",
    "CLIENT = 'client'\n",
    "_QUESTION = 'question'\n",
    "_ANSWER = 'answer'\n",
    "\n",
    "ANCHOR = 'anchor ids'\n",
    "POSITIVE = 'positive ids'\n",
    "NEGATIVE = 'negative ids'\n",
    "ANCHOR_TEXT = 'anchor'\n",
    "POSITIVE_TEXT = 'positive'\n",
    "NEGATIVE_TEXT = 'negative'\n",
    "\n",
    "DIALOGUE_SHEET = 'гн'\n",
    "FAQ_SHEET = 'FAQs'\n",
    "\n",
    "SBERT_MODEL = r'./sbert_large_nlu_ru'\n",
    "OUTPUT_MODEL = r'./triplet_loss_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01de242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _dict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f098f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(SBERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a73c6",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f27a64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NPF_FAQ_JSON, 'r', encoding='utf-8') as infile:\n",
    "    faq_dict = json.load(infile)\n",
    "    \n",
    "with open(QUESTION2FAQ, 'r', encoding='utf-8') as infile:\n",
    "    question2id = json.load(infile)\n",
    "    \n",
    "with open(ANSWER2FAQ, 'r', encoding='utf-8') as infile:\n",
    "    answer2id = json.load(infile)\n",
    "    \n",
    "with open(NPF_DIALOGUE_JSON, 'r', encoding='utf-8') as infile:\n",
    "    dialogue_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e145a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(_path):\n",
    "    def strip_text_data(df, field_lst):\n",
    "        for field in field_lst:\n",
    "            df[field] = df[field].map(lambda _: str(_).strip())\n",
    "        return df\n",
    "    \n",
    "    # reading the dialogue sheet\n",
    "    tagged_dialogues = pd.read_excel(_path, sheet_name=DIALOGUE_SHEET)\n",
    "    tagged_dialogues = strip_text_data(tagged_dialogues, [DIALOGUE, FAQ])\n",
    "    # reading the FAQs\n",
    "    faqs = pd.read_excel(_path, sheet_name=FAQ_SHEET)\n",
    "    faqs = strip_text_data(faqs, [QUESTION, ANSWER])\n",
    "    \n",
    "    return tagged_dialogues, faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e132ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/19704410/dialogue-to-faq/spacy-downgrade/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dialogues, faqs = load_data(INIT_DATA_TAGGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b967cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Диалог</th>\n",
       "      <th>FAQ</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>610722d4000000000a77c6f024670002</td>\n",
       "      <td>operator: меня зовут рита\\nclient: здравствуйт...</td>\n",
       "      <td>нет</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610726dd000000000a77c62723f80002</td>\n",
       "      <td>operator: алло максим здравствуйте\\nclient: зд...</td>\n",
       "      <td>нет</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61072ba5000500000a77c62723f80002</td>\n",
       "      <td>operator: меня зовут деда\\noperator: я вас слу...</td>\n",
       "      <td>Как получить выписку о состоянии пенсионного с...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61073228001100000a77c77724250002</td>\n",
       "      <td>operator: максим здравствуйте\\noperator: улице...</td>\n",
       "      <td>Как изменить персональные данные, указанные в ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61073327000400000a6d28a8239e0002</td>\n",
       "      <td>operator: сергей здравствуйте\\nclient: сергей ...</td>\n",
       "      <td>нет</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  610722d4000000000a77c6f024670002   \n",
       "1  610726dd000000000a77c62723f80002   \n",
       "2  61072ba5000500000a77c62723f80002   \n",
       "3  61073228001100000a77c77724250002   \n",
       "4  61073327000400000a6d28a8239e0002   \n",
       "\n",
       "                                              Диалог  \\\n",
       "0  operator: меня зовут рита\\nclient: здравствуйт...   \n",
       "1  operator: алло максим здравствуйте\\nclient: зд...   \n",
       "2  operator: меня зовут деда\\noperator: я вас слу...   \n",
       "3  operator: максим здравствуйте\\noperator: улице...   \n",
       "4  operator: сергей здравствуйте\\nclient: сергей ...   \n",
       "\n",
       "                                                 FAQ Unnamed: 3 Unnamed: 4  \\\n",
       "0                                                нет        NaN        NaN   \n",
       "1                                                нет        NaN        NaN   \n",
       "2  Как получить выписку о состоянии пенсионного с...        NaN        NaN   \n",
       "3  Как изменить персональные данные, указанные в ...        NaN        NaN   \n",
       "4                                                нет        NaN        NaN   \n",
       "\n",
       "  Unnamed: 5 Unnamed: 6  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c59da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Вопрос</th>\n",
       "      <th>Ответ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d50f98e783994ad0956ad50967543dbd</td>\n",
       "      <td>как передать в управление накопительную пенсию</td>\n",
       "      <td>В заявлении нужно указать, что управление ваши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945c4c9316f6460aa1ef2349ada0c7f2</td>\n",
       "      <td>В какие сроки банк зачисляет доход по Социальн...</td>\n",
       "      <td>Договор отрывается без участия работника путем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c494590c064e439da8386fb836f9c50b</td>\n",
       "      <td>В какие сроки банк зачисляет софинансирование ...</td>\n",
       "      <td>Софинансирование производится два раза в год: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505bf511bae14f10846b79225a872c8b</td>\n",
       "      <td>В какие сроки будет произведена срочная выплат...</td>\n",
       "      <td>Решение выносится по истечении 10 дней с даты ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150d3dfd81d547e5a57891d698196a12</td>\n",
       "      <td>В каким способом и в какие сроки пенсионный фо...</td>\n",
       "      <td>Решение о выплате по ОПС направляется в течени...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  d50f98e783994ad0956ad50967543dbd   \n",
       "1  945c4c9316f6460aa1ef2349ada0c7f2   \n",
       "2  c494590c064e439da8386fb836f9c50b   \n",
       "3  505bf511bae14f10846b79225a872c8b   \n",
       "4  150d3dfd81d547e5a57891d698196a12   \n",
       "\n",
       "                                              Вопрос  \\\n",
       "0     как передать в управление накопительную пенсию   \n",
       "1  В какие сроки банк зачисляет доход по Социальн...   \n",
       "2  В какие сроки банк зачисляет софинансирование ...   \n",
       "3  В какие сроки будет произведена срочная выплат...   \n",
       "4  В каким способом и в какие сроки пенсионный фо...   \n",
       "\n",
       "                                               Ответ  \n",
       "0  В заявлении нужно указать, что управление ваши...  \n",
       "1  Договор отрывается без участия работника путем...  \n",
       "2  Софинансирование производится два раза в год: ...  \n",
       "3  Решение выносится по истечении 10 дней с даты ...  \n",
       "4  Решение о выплате по ОПС направляется в течени...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faqs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44bc636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(_text):\n",
    "    _text = re.sub(\"\\n|(</?[^>]*>)\", \" \", _text)\n",
    "    _text = re.sub('здравствуйте', '', _text)\n",
    "    _text = re.sub('добрый день', '', _text)\n",
    "    _text = re.sub(r\"\\s+\", \" \", _text)\n",
    "    return _text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "604e22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid FAQ ID: nan\n"
     ]
    }
   ],
   "source": [
    "triplet_dict = dict()\n",
    "\n",
    "with jl.open(TRIPLET_DATA, mode='w') as outfile:\n",
    "    # Filling in the anchor FAQ questions\n",
    "    for _id in faqs[ID]:\n",
    "        triplet_dict[_id] = {\n",
    "            ANCHOR: set(),\n",
    "            ANCHOR_TEXT: [],\n",
    "            POSITIVE: set(),\n",
    "            POSITIVE_TEXT: [],\n",
    "            NEGATIVE: set(),\n",
    "            NEGATIVE_TEXT: []\n",
    "        }\n",
    "        try:\n",
    "            _question = faq_dict[_id][_QUESTION]\n",
    "            triplet_dict[_id][ANCHOR].add(_id)\n",
    "            triplet_dict[_id][ANCHOR_TEXT].append(_question)\n",
    "        except Exception:\n",
    "            print('Invalid FAQ ID:', _id)\n",
    "    # Filling in the positive examples\n",
    "    for idx, row in dialogues.iterrows():\n",
    "        if row[FAQ] == 'нет':\n",
    "            continue\n",
    "        _id = row[ID]  # Dialogue ID\n",
    "        _question = row[FAQ]\n",
    "        try:\n",
    "            client_lines = dialogue_dict[_id][CLIENT]\n",
    "            _client = clean_text(' '.join(client_lines))\n",
    "            faq_id = question2id[_question]\n",
    "            assert triplet_dict.get(faq_id) is not None\n",
    "            triplet_dict[faq_id][POSITIVE].add(_id)\n",
    "            triplet_dict[faq_id][POSITIVE_TEXT].append(_client)\n",
    "        except Exception:\n",
    "            print('Invalid dialogue ID:', _id)\n",
    "    # Filling in the negative examples\n",
    "    dialogue_id_set = set(dialogue_dict.keys())\n",
    "    for faq_id in faqs[ID]:\n",
    "        if not triplet_dict[faq_id][POSITIVE]:\n",
    "            triplet_dict.pop(faq_id, None)\n",
    "            continue\n",
    "        negative_candidates = dialogue_id_set - triplet_dict[faq_id][POSITIVE]\n",
    "        triplet_dict[faq_id][NEGATIVE] = sample(negative_candidates,\n",
    "                                                len(triplet_dict[faq_id][POSITIVE]))\n",
    "        _question = faq_dict[faq_id][_QUESTION]\n",
    "        for _id in triplet_dict[faq_id][NEGATIVE]:\n",
    "            client_lines = dialogue_dict[_id][CLIENT]\n",
    "            _client = clean_text(' '.join(client_lines))\n",
    "            faq_id = question2id[_question]\n",
    "            assert triplet_dict.get(faq_id) is not None\n",
    "            triplet_dict[faq_id][NEGATIVE_TEXT].append(_client)\n",
    "            \n",
    "    # Dumping the triplet items\n",
    "    for triplet_item in triplet_dict.values():\n",
    "        triplet_item.pop(ANCHOR, None)\n",
    "        triplet_item.pop(POSITIVE, None)\n",
    "        triplet_item.pop(NEGATIVE, None)\n",
    "        outfile.write(triplet_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f07a24",
   "metadata": {},
   "source": [
    "# Preprocessed Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca7c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "\n",
    "with jl.open(TRIPLET_DATA, mode='r') as infile:\n",
    "    for item in infile:\n",
    "        raw_data.append(item)\n",
    "        \n",
    "train_data, val_test_data = train_test_split(raw_data, test_size=0.3, random_state=1)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be47f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, _data, labels):\n",
    "        assert _data.input_ids.shape == _data.token_type_ids.shape == \\\n",
    "               _data.attention_mask.shape\n",
    "        assert _data.input_ids.shape[0] % 3 == 0\n",
    "        \n",
    "        triplet_len = _data.input_ids.shape[0] // 3\n",
    "        \n",
    "        anchors = self.triplet_item(_data, 0, triplet_len)\n",
    "        positives = self.triplet_item(_data, 1, triplet_len)\n",
    "        negatives = self.triplet_item(_data, 2, triplet_len)\n",
    "        \n",
    "        input_ids, token_type_ids, attention_mask = [], [], []\n",
    "        for i in range(triplet_len):\n",
    "            # input token IDs\n",
    "            triplet = torch.stack((anchors.input_ids[i, :],\n",
    "                                   positives.input_ids[i, :],\n",
    "                                   negatives.input_ids[i, :]), 0)\n",
    "            input_ids.append(triplet)\n",
    "            # token type IDs\n",
    "            triplet = torch.stack((anchors.token_type_ids[i, :],\n",
    "                                   positives.token_type_ids[i, :],\n",
    "                                   negatives.token_type_ids[i, :]), 0)\n",
    "            token_type_ids.append(triplet)\n",
    "            # attention mask\n",
    "            triplet = torch.stack((anchors.attention_mask[i, :],\n",
    "                                   positives.attention_mask[i, :],\n",
    "                                   negatives.attention_mask[i, :]), 0)\n",
    "            attention_mask.append(triplet)\n",
    "            \n",
    "        self.features = BatchEncoding(_dict(input_ids=torch.stack(input_ids, 0),\n",
    "                                      token_type_ids=torch.stack(token_type_ids, 0),\n",
    "                                      attention_mask=torch.stack(attention_mask, 0)))\n",
    "        self.targets = torch.tensor(labels).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.input_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        _features = BatchEncoding(_dict(input_ids=self.features.input_ids[idx, :, :],\n",
    "                                  token_type_ids=self.features.token_type_ids[idx, :, :],\n",
    "                                  attention_mask=self.features.attention_mask[idx, :, :]))\n",
    "        _label = self.targets[idx, :]\n",
    "        return (_features, _label)\n",
    "    \n",
    "    @staticmethod\n",
    "    def triplet_item(_data, item_type, triplet_len):\n",
    "        left, right = triplet_len * item_type, triplet_len * (item_type + 1)\n",
    "        res_item = BatchEncoding(_dict(\n",
    "                                 input_ids=_data.input_ids[left:right, :],\n",
    "                                 token_type_ids=_data.token_type_ids[left:right, :],\n",
    "                                 attention_mask=_data.attention_mask[left:right, :]\n",
    "        ))\n",
    "        return res_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5bcf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSet:\n",
    "    def __init__(self, train_data, val_data, batch_size=32):\n",
    "        kwargs = self.make_kwargs()\n",
    "        \n",
    "        train_texts, train_labels = self.make_triplets(train_data)\n",
    "        val_texts, val_labels = self.make_triplets(val_data)\n",
    "        \n",
    "        self.train_set = TripletDataset(train_texts, train_labels)\n",
    "        self.train_loader = DataLoader(self.train_set, batch_size=batch_size,\n",
    "                                     drop_last=True, shuffle=True, **kwargs)\n",
    "        self.val_set = TripletDataset(val_texts, val_labels)\n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=batch_size,\n",
    "                                    drop_last=True, shuffle=True, **kwargs)\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_token_ids(_text, seq_len=64, _padding=True,\n",
    "                      _truncation=True, tensor_type='pt'):\n",
    "        tokenized_text = tokenizer(_text, padding=_padding, truncation=_truncation,\n",
    "                                  max_length=seq_len, return_tensors=tensor_type)\n",
    "        return tokenized_text\n",
    "    \n",
    "    def make_triplets(self, _data):\n",
    "        anchors, positives, negatives = [], [], []\n",
    "        \n",
    "        for raw_item in _data:\n",
    "            assert len(raw_item[POSITIVE_TEXT]) == len(raw_item[NEGATIVE_TEXT])\n",
    "            for i in range(len(raw_item[POSITIVE_TEXT])):\n",
    "                anchors.append(raw_item[ANCHOR_TEXT][0])\n",
    "                positives.append(raw_item[POSITIVE_TEXT][i])\n",
    "                negatives.append(raw_item[NEGATIVE_TEXT][i])\n",
    "                \n",
    "        labels = np.ones((len(anchors), 1))\n",
    "        all_texts = anchors + positives + negatives\n",
    "        tokenized_texts = self.get_token_ids(all_texts)\n",
    "        \n",
    "        return tokenized_texts, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_kwargs():\n",
    "        # TODO deal with pin_memory for custom datasets\n",
    "        use_cuda = False # torch.cuda.is_available()\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "        return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224a72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLoss(nn.Module):\n",
    "    def __init__(self, _loss=(lambda _: F.relu(_))):\n",
    "        super(SoftmaxLoss, self).__init__()\n",
    "        self.loss_func = _loss\n",
    "    \n",
    "    def forward(self, anchor, positive, negative, is_test=False):\n",
    "        positive_similarity = torch.sum(anchor * positive, axis=-1, keepdims=True)\n",
    "        _matmul = torch.matmul(anchor, torch.transpose(negative, 0, 1))\n",
    "        negative_similarity = torch.log(torch.sum(\n",
    "            torch.exp(_matmul), axis=-1, keepdims=True))\n",
    "        loss = self.loss_func(negative_similarity - positive_similarity)\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_loss(_true, _predicted):\n",
    "        _mean = torch.mean(_predicted - 0 * _true, dim=0)\n",
    "        return _mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "126a0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletModel(nn.Module):\n",
    "    def __init__(self, model_path=SBERT_MODEL):\n",
    "        super(TripletModel, self).__init__()\n",
    "        self.sbert = AutoModel.from_pretrained(model_path)\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        \n",
    "    def forward(self, _input, c=0.5):\n",
    "        _input = BatchEncoding(_input)\n",
    "        anchor_input = self.fetch_triplet_item(_input, 0)\n",
    "        positive_input = self.fetch_triplet_item(_input, 1)\n",
    "        negative_input = self.fetch_triplet_item(_input, 2)\n",
    "        \n",
    "        encoded_anchor = self.mean_pooling(self.sbert(**anchor_input),\n",
    "                                          anchor_input.attention_mask) * c\n",
    "        encoded_positive = self.mean_pooling(self.sbert(**positive_input),\n",
    "                                            positive_input.attention_mask) * c\n",
    "        encoded_negative = self.mean_pooling(self.sbert(**negative_input),\n",
    "                                            negative_input.attention_mask) * c\n",
    "        cosine_pos = self.cos(encoded_anchor, encoded_positive)\n",
    "        cosine_neg = self.cos(encoded_anchor, encoded_negative)\n",
    "        return encoded_anchor, encoded_positive, encoded_negative, (cosine_pos, cosine_neg)\n",
    "        \n",
    "    @staticmethod\n",
    "    def mean_pooling(_output, attention_mask):\n",
    "        token_embeddings = _output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(\n",
    "            token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def fetch_triplet_item(_input, item_idx):\n",
    "        res_item = BatchEncoding(_dict(\n",
    "            input_ids=_input.input_ids[:, item_idx, :],\n",
    "            token_type_ids=_input.token_type_ids[:, item_idx, :],\n",
    "            attention_mask=_input.attention_mask[:, item_idx, :]\n",
    "        ))\n",
    "        return res_item\n",
    "    \n",
    "    def cos(self, u, v):\n",
    "        return self.cosine_similarity(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8119c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPipeline:\n",
    "    def __init__(self, _dataset, _model, _criterion, _optimizer, _device='cpu'):\n",
    "        self.dataset = _dataset\n",
    "        self.model = _model\n",
    "        self.criterion = _criterion\n",
    "        self.optimizer = _optimizer\n",
    "        self.device = torch.device(_device)\n",
    "        \n",
    "        self.best = defaultdict(int)\n",
    "        \n",
    "    def fit(self, epoch_num, log_interval=5):\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        \n",
    "        num_steps = epoch_num * len(self.dataset.train_loader)\n",
    "        lr_scheduler = get_scheduler(name='linear', optimizer=self.optimizer,\n",
    "                                    num_warmup_steps=0, num_training_steps=num_steps)\n",
    "        \n",
    "        # TODO deal with IProgress\n",
    "        # progress_bar = tqdm(range(num_steps))\n",
    "        \n",
    "        for epoch in range(epoch_num):\n",
    "            mean_epoch_loss = self.train_epoch(lr_scheduler)\n",
    "            print(\"Epoch #{epoch_num}\\nMean epoch loss: {mean_loss}\".format(\n",
    "                    epoch_num=epoch + 1, mean_loss=mean_epoch_loss))\n",
    "                \n",
    "            if (epoch + 1) % log_interval == 0 or epoch == 0:\n",
    "                print()\n",
    "                self.validate()\n",
    "                print()\n",
    "                \n",
    "    @staticmethod\n",
    "    def mean_loss(_true, _predicted):\n",
    "        _mean = torch.mean(_predicted - 0 * _true, dim=0)\n",
    "        return _mean\n",
    "    \n",
    "    def train_epoch(self, lr_scheduler):\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        \n",
    "        epoch_loss = []\n",
    "        for batch, (_input, _target) in enumerate(self.dataset.train_loader):\n",
    "            # TODO method to transfer _input to device\n",
    "            # _input, _target = _input.to(self.device), _target.to(self.device)\n",
    "            anchor, positive, negative, _ = self.model(_input)\n",
    "            _loss = self.criterion(anchor, positive, negative)\n",
    "            mean_loss = self.mean_loss(_loss, _loss)\n",
    "\n",
    "            epoch_loss.append(mean_loss.item())\n",
    "            mean_loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            # progress_bar.update(1)\n",
    "                \n",
    "        return sum(epoch_loss) / len(epoch_loss)\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cosine_dist, targets = [], []\n",
    "            for _input, _target in self.dataset.val_loader:\n",
    "                _, _, _, cos = self.model(_input)\n",
    "                cosine_dist.append(cos[0])\n",
    "                cosine_dist.append(cos[1])\n",
    "                targets.append(_target)\n",
    "                targets.append(_target * 0)\n",
    "            cosine_dist = torch.cat(cosine_dist).detach().numpy()\n",
    "            targets = torch.cat(targets)\n",
    "            targets = torch.squeeze(targets).detach().numpy()\n",
    "\n",
    "        for metric, func in [(\"spearman_r\", spearmanr), (\"pearson_r\", pearsonr)]:\n",
    "            coef, _ = func(targets, cosine_dist)\n",
    "            coef = np.round(coef, 4)\n",
    "\n",
    "            metric_name = f\"{metric}\"\n",
    "            message = f\"{metric_name} = {coef}\"\n",
    "            if coef > self.best[metric_name]:\n",
    "                self.best[metric_name] = coef\n",
    "                message = \"*** New best: \" + message\n",
    "                if metric == \"spearman_r\":\n",
    "                    torch.save(self.model.state_dict(), OUTPUT_MODEL)\n",
    "\n",
    "            print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c629317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TripletSet(train_data, val_data)\n",
    "model = TripletModel()\n",
    "criterion = SoftmaxLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "evaluation_pipeline = ModelPipeline(_dataset=dataset, _model=model,\n",
    "                                   _criterion=criterion, _optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48414948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\n",
      "Mean epoch loss: 4.020175554535606\n",
      "\n",
      "*** New best: spearman_r = 0.1887\n",
      "*** New best: pearson_r = 0.1755\n",
      "\n",
      "Epoch #2\n",
      "Mean epoch loss: 2.2606953219933943\n",
      "Epoch #3\n",
      "Mean epoch loss: 1.6565082235769792\n",
      "Epoch #4\n",
      "Mean epoch loss: 1.129652207547968\n",
      "Epoch #5\n",
      "Mean epoch loss: 0.7738909016955983\n",
      "\n",
      "*** New best: spearman_r = 0.2572\n",
      "*** New best: pearson_r = 0.2471\n",
      "\n",
      "Epoch #6\n",
      "Mean epoch loss: 0.42020295424894855\n",
      "Epoch #7\n",
      "Mean epoch loss: 0.2411789677359841\n",
      "Epoch #8\n",
      "Mean epoch loss: 0.16618689623746005\n",
      "Epoch #9\n",
      "Mean epoch loss: 0.10451420870694247\n",
      "Epoch #10\n",
      "Mean epoch loss: 0.095385957847942\n",
      "\n",
      "*** New best: spearman_r = 0.328\n",
      "*** New best: pearson_r = 0.3069\n",
      "\n",
      "Epoch #11\n",
      "Mean epoch loss: 0.13102248040112582\n",
      "Epoch #12\n",
      "Mean epoch loss: 0.04371857101267034\n",
      "Epoch #13\n",
      "Mean epoch loss: 0.04948553172024814\n",
      "Epoch #14\n",
      "Mean epoch loss: 0.04179584438150579\n"
     ]
    }
   ],
   "source": [
    "evaluation_pipeline.fit(epoch_num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d80e455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [i % 2 for i in range(1, 11)]\n",
    "b = torch.tensor(b).float()\n",
    "b = torch.unsqueeze(b, 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85ebc779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.5000],\n",
       "        [0.3333],\n",
       "        [0.2500],\n",
       "        [0.2000],\n",
       "        [0.1667],\n",
       "        [0.1429],\n",
       "        [0.1250],\n",
       "        [0.1111],\n",
       "        [0.1000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i ** -1 for i in range(1, 11)]\n",
    "a = torch.tensor(a).float()\n",
    "a = torch.unsqueeze(a, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a817337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.5       ],\n",
       "       [0.33333334],\n",
       "       [0.25      ],\n",
       "       [0.2       ],\n",
       "       [0.16666667],\n",
       "       [0.14285715],\n",
       "       [0.125     ],\n",
       "       [0.11111111],\n",
       "       [0.1       ]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.detach().numpy()\n",
    "b = b.detach().numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c600b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44ad12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.17407765595569785, pvalue=0.6305360755569764)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = spearmanr(b, a)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a7a869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea78b3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/vvxc5ydj60z5srd_vtjxrvqnb7ggnh/T/ipykernel_52179/4243538915.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(b).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(b).float()\n",
    "b[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026560c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(SBERT_MODEL)\n",
    "model = AutoModel.from_pretrained(SBERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de54683",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Привет! Как твои дела?',\n",
    "             'А правда, что 42 твое любимое число?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d325a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=24, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9669fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f620d26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21279c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0363c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 19:02:16.977766: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 1.2989, -0.5805,  0.6631],\n",
       "       [-0.6603,  0.3014,  1.9022],\n",
       "       [ 0.0637,  2.7615, -1.6628],\n",
       "       [-0.3582,  0.0641, -0.918 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.2989, -0.5805,  0.6631],\n",
    "                [-0.6603,  0.3014,  1.9022],\n",
    "                [0.0637,  2.7615, -1.6628],\n",
    "                [-0.3582,  0.0641, -0.9180]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc70c365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.1118,  0.1751, -0.3803],\n",
       "       [-0.4642,  0.7397,  0.5235],\n",
       "       [ 0.1512,  1.4405,  0.8461],\n",
       "       [ 0.2314, -0.8797,  0.0437]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([[-0.1118,  0.1751, -0.3803],\n",
    "                [-0.4642,  0.7397,  0.5235],\n",
    "                [0.1512,  1.4405,  0.8461],\n",
    "                [0.2314, -0.8797,  0.0437]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "483c4f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.14521702, -0.10164555, -0.2521769 ],\n",
       "       [ 0.30651125,  0.22294559,  0.99580175],\n",
       "       [ 0.00963144,  3.9779406 , -1.406895  ],\n",
       "       [-0.08288749, -0.05638877, -0.0401166 ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7742bfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy-downgrade",
   "language": "python",
   "name": "spacy-downgrade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
