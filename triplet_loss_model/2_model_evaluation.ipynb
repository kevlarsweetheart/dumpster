{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efremova-ma/search_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-10-18 11:45:31.543832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-18 11:45:31.543865: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import jsonlines as jl\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Paths and files\n",
    "#################\n",
    "\n",
    "# Data paths\n",
    "INPUT_PATH = Path(\"..\")/\"input\"\n",
    "TEST_TRIPLES = Path(INPUT_PATH)/\"test_triples.jsonl\"\n",
    "\n",
    "# Model paths\n",
    "OUTPUT_PATH = Path(\"..\")/\"result\"\n",
    "FASTTEXT = \"./ft_all_phr_2022_30_03_top_100000.pkl\"\n",
    "FIT_TOKENIZER = Path(OUTPUT_PATH)/\"ft_tokenizer.pkl\"\n",
    "MODEL = Path(OUTPUT_PATH)/\"triplet_loss_model.sav\"\n",
    "\n",
    "###########\n",
    "# Сonstants\n",
    "###########\n",
    "\n",
    "# Data fields\n",
    "ANCHOR = \"anchor\"\n",
    "POSITIVE = \"positive\"\n",
    "NEGATIVE = \"negative\"\n",
    "TYPE2IDX = dict(anchor=0, positive=1, negative=2)\n",
    "\n",
    "# Devices and threads\n",
    "GPU_NUM = torch.cuda.device_count()\n",
    "GPU_IDS = [f'cuda:{_id}' for _id in range(GPU_NUM)]\n",
    "\n",
    "# Model parameters\n",
    "VOCAB_SIZE = 20000\n",
    "EMBEDDING_SIZE = 300\n",
    "LSTM_SIZE = 128\n",
    "LSTM_NUM_LAYERS = 3\n",
    "OUT_EMBEDDING_SIZE = 768\n",
    "MAX_SEQ_LEN = 32\n",
    "\n",
    "ANCHOR_NUM = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triples(_file):\n",
    "    with jl.open(_file, mode=\"r\") as infile:\n",
    "        triple_lst = [item for item in infile]\n",
    "    return triple_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FIT_TOKENIZER, \"rb\") as infile:\n",
    "    TOKENIZER = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triples = load_triples(TEST_TRIPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_unique_texts(_file):\n",
    "    with jl.open(_file, mode=\"r\") as infile:\n",
    "        unique_texts = [{item[ANCHOR], item[POSITIVE], item[NEGATIVE]} for item in infile]\n",
    "        unique_texts = list(set().union(*unique_texts))\n",
    "    return unique_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоги радиоспортивной олимпиады \"Первенство России среди молодежи 2007 года\".\n",
      "\n",
      "И я хотел для себя секретное место.\n",
      "\n",
      "Через несколько секунд происходит третья стадия высвобождения, и прозрачное водяное вещество, которое является секретом простаты, выпускается снова.\n",
      "\n",
      "Публичное администрирование – политические науки» (программа двойных дипломов).\n",
      "\n",
      "Министерством обороны было принято решение об организации серийного производства автомата Калашникова на Ижевском машиностроительном заводе, к тому времени более 140 лет выпускавшем стрелковое оружие.\n"
     ]
    }
   ],
   "source": [
    "# Texts from the test corpus\n",
    "unique_texts = fetch_unique_texts(TEST_TRIPLES)\n",
    "print(\"\\n\\n\".join(unique_texts[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2idx = {\n",
    "    text: str(_id + 1) for _id, text in enumerate(unique_texts)\n",
    "}\n",
    "\n",
    "idx2text = {\n",
    "    _id: text for text, _id in text2idx.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "class _dict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return self.__dict__\n",
    "    \n",
    "    def __setstate__(self, d):\n",
    "        return self.__dict__.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossModel(nn.Module):\n",
    "    def __init__(self, criterion=None,\n",
    "                 init_weights=None,\n",
    "                 emb_size=EMBEDDING_SIZE, vocab_size=VOCAB_SIZE,\n",
    "                 lstm_num_layers=LSTM_NUM_LAYERS,\n",
    "                 lstm_hidden_size=LSTM_SIZE, is_bi=True,\n",
    "                 out_emb_size=OUT_EMBEDDING_SIZE,\n",
    "                 batch_first=True, dropout=0.2, norm_eps=1e-12):\n",
    "        super(TripletLossModel, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.emb_size = emb_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.directions = int(is_bi) + 1\n",
    "        self.out_emb_size = out_emb_size\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = nn.Embedding(self.vocab_size + 1, self.emb_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.emb_size, hidden_size=self.lstm_hidden_size,\n",
    "                            num_layers=self.lstm_num_layers, bidirectional=is_bi,\n",
    "                            batch_first=batch_first, dropout=dropout)\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        \n",
    "        self.best = defaultdict(int)\n",
    "        \n",
    "    def forward(self, _input):\n",
    "        anchor_input = self.fetch_triplet_item(_input, ANCHOR)\n",
    "        positive_input = self.fetch_triplet_item(_input, POSITIVE)\n",
    "        negative_input = self.fetch_triplet_item(_input, NEGATIVE)\n",
    "        \n",
    "        encoded_anchor = self.encode(anchor_input)\n",
    "        encoded_positive = self.encode(positive_input)\n",
    "        encoded_negative = self.encode(negative_input)\n",
    "        \n",
    "        cosine_pos = self.cos(encoded_anchor, encoded_positive)\n",
    "        cosine_neg = self.cos(encoded_anchor, encoded_negative)\n",
    "        \n",
    "        return _dict(anchor=encoded_anchor,\n",
    "                    positive=encoded_positive,\n",
    "                    negative=encoded_negative,\n",
    "                    cos_sim=(cosine_pos, cosine_neg))\n",
    "        \n",
    "    def encode(self, tokenized_seq, _const=0.5):\n",
    "        encoded_seq = self.embedding(tokenized_seq)\n",
    "        encoded_seq, _ = self.lstm(encoded_seq)\n",
    "        encoded_seq = encoded_seq[:, -1, :] * _const\n",
    "        return encoded_seq\n",
    "        \n",
    "    @staticmethod\n",
    "    def fetch_triplet_item(_input, item_type):\n",
    "        if TYPE2IDX.get(item_type) is None:\n",
    "            raise Exception(f\"No item type {item_type}\")\n",
    "        return _input[:, TYPE2IDX[item_type], :]\n",
    "    \n",
    "    def cos(self, u, v):\n",
    "        return self.cosine_similarity(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRR Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = TripletLossModel()\n",
    "_model.load_state_dict(torch.load(MODEL, map_location=torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_arbitrary_texts(texts):\n",
    "    indexed_data = TOKENIZER.texts_to_sequences(texts)\n",
    "    max_seq_len = MAX_SEQ_LEN\n",
    "        \n",
    "    # Filling the padded matrix\n",
    "    _size = len(texts)\n",
    "    out_matrix = torch.zeros((_size, max_seq_len), dtype=torch.int64)\n",
    "    for idx in range(_size):\n",
    "        bound = min(len(indexed_data[idx]), max_seq_len)\n",
    "        out_matrix[idx, :bound] = torch.from_numpy(\n",
    "            np.array(indexed_data[idx][:bound]))\n",
    "        \n",
    "    text_embeddings = _model.encode(out_matrix)\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282930/282930 [1:48:42<00:00, 43.38it/s]  \n"
     ]
    }
   ],
   "source": [
    "idx2embedding = {\n",
    "    _id: encode_arbitrary_texts([text]) for _id, text in tqdm(idx2text.items(), total=282930)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [1:38:01<00:00, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 on test: 0.449986342536033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "\n",
    "for item in tqdm(test_triples[:ANCHOR_NUM], total=ANCHOR_NUM):\n",
    "    anchor_id = text2idx[item[ANCHOR]]\n",
    "    anchor_embedding = idx2embedding[anchor_id]\n",
    "    idx2cos = {\n",
    "        sample_id: _model.cos(anchor_embedding, sample_embedding).item()\n",
    "        for sample_id, sample_embedding in idx2embedding.items() if sample_id != anchor_id\n",
    "    }\n",
    "    idx2cos = {_id: _cos for _id, _cos in sorted(list(idx2cos.items()), key=lambda _: _[1], reverse=True)}\n",
    "    sampled_ids = list(idx2cos.keys())[:20]\n",
    "    \n",
    "    positive_id = text2idx[item[POSITIVE]]\n",
    "    if positive_id not in sampled_ids:\n",
    "        ranks.append(0.0)\n",
    "    else:\n",
    "        ranks.append(1 / (sampled_ids.index(positive_id) + 1))\n",
    "        \n",
    "print(\"MRR@20 on test:\", sum(ranks) / len(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_env",
   "language": "python",
   "name": "search_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
